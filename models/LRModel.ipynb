{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZZQukctFfK6",
        "outputId": "3db189f3-41f2-4038-f8d9-91f5152897c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMbHgcPmFk8I"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "import pprint\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SD2efFeoGRtH"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/creditcard.csv')\n",
        "df = df.rename(columns={'Class': 'Fraud'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEPy95eSJ_co"
      },
      "outputs": [],
      "source": [
        "df['Fraud'] = df['Fraud'].astype(int)\n",
        "\n",
        "X = df.drop(['Fraud'], axis = 1)\n",
        "Y = df[\"Fraud\"]\n",
        "\n",
        "xData = X.values\n",
        "yData = Y.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1BNq8V0JCa8"
      },
      "outputs": [],
      "source": [
        "xTrain, xTest, yTrain, yTest = train_test_split(\n",
        "        xData, yData, test_size = 0.2, random_state = 42)\n",
        "\n",
        "pipe = Pipeline([('standardScaler', StandardScaler()), ('quantiletransformer', QuantileTransformer()), ('logistic_regression', LogisticRegression())])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFI5Tz4QKGet",
        "outputId": "b35a1f20-614c-43a9-8aba-bd9fccd9e42a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((227845, 30), (56962, 30), (227845,), (56962,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "xTrain.shape, xTest.shape, yTrain.shape, yTest.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkiiaxUxInav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f850791-cdfd-463a-e6eb-5f98338630c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:703: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('standardScaler', StandardScaler()),\n",
              "                                       ('quantiletransformer',\n",
              "                                        QuantileTransformer()),\n",
              "                                       ('logistic_regression',\n",
              "                                        LogisticRegression())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid=[{'logistic_regression__C': [0.01, 0.1, 1.0, 10.0,\n",
              "                                                     100.0],\n",
              "                          'logistic_regression__penalty': ['l2'],\n",
              "                          'logistic_regression__solver': ['newton-cg', 'lbfgs',\n",
              "                                                          'liblinear', 'sag',\n",
              "                                                          'saga']}],\n",
              "             scoring='recall', verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "param_grid_pspp = [{\n",
        "    'logistic_regression__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "    'logistic_regression__C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
        "    'logistic_regression__penalty': ['l2']\n",
        "}]\n",
        "\n",
        "grid_search_pspp = GridSearchCV(pipe, param_grid_pspp, cv=5, scoring= 'recall', verbose=2, n_jobs=-1)\n",
        "grid_search_pspp.fit(xTrain, yTrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wchYcSjKLoxz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5d7053d-da52-4ab0-e872-9cb0122d2926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'mean_fit_time': array([ 5.61145859,  3.54838786,  4.29658179,  4.91125631,  5.34654608,\n",
            "        6.37752495,  4.21260753,  4.02222228,  5.27567477, 10.22523756,\n",
            "        7.39283924,  4.81795459,  4.56169333,  7.06898284, 13.77252846,\n",
            "        7.81372771,  5.18265414,  4.89906025,  8.29845471, 15.66867495,\n",
            "        7.88574333,  5.51786485,  5.05793619,  8.94274349, 16.36387954]),\n",
            " 'mean_score_time': array([0.43639269, 0.44243989, 0.50339742, 0.41421494, 0.42965169,\n",
            "       0.43896551, 0.41601362, 0.41080809, 0.40075579, 0.48201661,\n",
            "       0.42961645, 0.43053937, 0.41668172, 0.39964752, 0.40363965,\n",
            "       0.42514834, 0.4056612 , 0.39823723, 0.37792201, 0.39890742,\n",
            "       0.44397483, 0.41767049, 0.42583599, 0.3954783 , 0.37329655]),\n",
            " 'mean_test_score': array([0.        , 0.        , 0.03050957, 0.        , 0.        ,\n",
            "       0.69308666, 0.69308666, 0.70574489, 0.69308666, 0.69308666,\n",
            "       0.76153846, 0.76153846, 0.76153846, 0.76153846, 0.76153846,\n",
            "       0.76660175, 0.76660175, 0.76660175, 0.76660175, 0.76660175,\n",
            "       0.76660175, 0.76660175, 0.76660175, 0.76660175, 0.76660175]),\n",
            " 'param_logistic_regression__C': masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
            "                   1.0, 1.0, 1.0, 1.0, 1.0, 10.0, 10.0, 10.0, 10.0, 10.0,\n",
            "                   100.0, 100.0, 100.0, 100.0, 100.0],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False],\n",
            "       fill_value='?',\n",
            "            dtype=object),\n",
            " 'param_logistic_regression__penalty': masked_array(data=['l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
            "                   'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
            "                   'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False],\n",
            "       fill_value='?',\n",
            "            dtype=object),\n",
            " 'param_logistic_regression__solver': masked_array(data=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',\n",
            "                   'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',\n",
            "                   'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',\n",
            "                   'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',\n",
            "                   'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False],\n",
            "       fill_value='?',\n",
            "            dtype=object),\n",
            " 'params': [{'logistic_regression__C': 0.01,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'newton-cg'},\n",
            "            {'logistic_regression__C': 0.01,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'lbfgs'},\n",
            "            {'logistic_regression__C': 0.01,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'liblinear'},\n",
            "            {'logistic_regression__C': 0.01,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'sag'},\n",
            "            {'logistic_regression__C': 0.01,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'saga'},\n",
            "            {'logistic_regression__C': 0.1,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'newton-cg'},\n",
            "            {'logistic_regression__C': 0.1,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'lbfgs'},\n",
            "            {'logistic_regression__C': 0.1,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'liblinear'},\n",
            "            {'logistic_regression__C': 0.1,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'sag'},\n",
            "            {'logistic_regression__C': 0.1,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'saga'},\n",
            "            {'logistic_regression__C': 1.0,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'newton-cg'},\n",
            "            {'logistic_regression__C': 1.0,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'lbfgs'},\n",
            "            {'logistic_regression__C': 1.0,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'liblinear'},\n",
            "            {'logistic_regression__C': 1.0,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'sag'},\n",
            "            {'logistic_regression__C': 1.0,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'saga'},\n",
            "            {'logistic_regression__C': 10.0,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'newton-cg'},\n",
            "            {'logistic_regression__C': 10.0,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'lbfgs'},\n",
            "            {'logistic_regression__C': 10.0,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'liblinear'},\n",
            "            {'logistic_regression__C': 10.0,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'sag'},\n",
            "            {'logistic_regression__C': 10.0,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'saga'},\n",
            "            {'logistic_regression__C': 100.0,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'newton-cg'},\n",
            "            {'logistic_regression__C': 100.0,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'lbfgs'},\n",
            "            {'logistic_regression__C': 100.0,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'liblinear'},\n",
            "            {'logistic_regression__C': 100.0,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'sag'},\n",
            "            {'logistic_regression__C': 100.0,\n",
            "             'logistic_regression__penalty': 'l2',\n",
            "             'logistic_regression__solver': 'saga'}],\n",
            " 'rank_test_score': array([22, 22, 21, 22, 22, 17, 17, 16, 17, 17, 11, 11, 11, 11, 11,  1,  1,\n",
            "        1,  1,  1,  1,  1,  1,  1,  1], dtype=int32),\n",
            " 'split0_test_score': array([0.        , 0.        , 0.05128205, 0.        , 0.        ,\n",
            "       0.76923077, 0.76923077, 0.76923077, 0.76923077, 0.76923077,\n",
            "       0.80769231, 0.80769231, 0.80769231, 0.80769231, 0.80769231,\n",
            "       0.80769231, 0.80769231, 0.80769231, 0.80769231, 0.80769231,\n",
            "       0.80769231, 0.80769231, 0.80769231, 0.80769231, 0.80769231]),\n",
            " 'split1_test_score': array([0.        , 0.        , 0.03797468, 0.        , 0.        ,\n",
            "       0.60759494, 0.60759494, 0.63291139, 0.60759494, 0.60759494,\n",
            "       0.69620253, 0.69620253, 0.70886076, 0.69620253, 0.69620253,\n",
            "       0.69620253, 0.69620253, 0.69620253, 0.69620253, 0.69620253,\n",
            "       0.69620253, 0.69620253, 0.69620253, 0.69620253, 0.69620253]),\n",
            " 'split2_test_score': array([0.        , 0.        , 0.03797468, 0.        , 0.        ,\n",
            "       0.6835443 , 0.6835443 , 0.6835443 , 0.6835443 , 0.6835443 ,\n",
            "       0.73417722, 0.73417722, 0.72151899, 0.73417722, 0.73417722,\n",
            "       0.73417722, 0.73417722, 0.73417722, 0.73417722, 0.73417722,\n",
            "       0.73417722, 0.73417722, 0.73417722, 0.73417722, 0.73417722]),\n",
            " 'split3_test_score': array([0.        , 0.        , 0.02531646, 0.        , 0.        ,\n",
            "       0.69620253, 0.69620253, 0.69620253, 0.69620253, 0.69620253,\n",
            "       0.7721519 , 0.7721519 , 0.7721519 , 0.7721519 , 0.7721519 ,\n",
            "       0.79746835, 0.79746835, 0.79746835, 0.79746835, 0.79746835,\n",
            "       0.79746835, 0.79746835, 0.79746835, 0.79746835, 0.79746835]),\n",
            " 'split4_test_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.70886076, 0.70886076, 0.74683544, 0.70886076, 0.70886076,\n",
            "       0.79746835, 0.79746835, 0.79746835, 0.79746835, 0.79746835,\n",
            "       0.79746835, 0.79746835, 0.79746835, 0.79746835, 0.79746835,\n",
            "       0.79746835, 0.79746835, 0.79746835, 0.79746835, 0.79746835]),\n",
            " 'std_fit_time': array([0.24419527, 0.12041142, 0.754321  , 0.38297475, 0.37244431,\n",
            "       0.19865903, 0.12113687, 0.06593424, 0.28333972, 0.81232232,\n",
            "       0.59639103, 0.19921965, 0.07543939, 0.57691366, 1.054908  ,\n",
            "       0.40510468, 0.28839516, 0.08423457, 0.32181936, 0.9888351 ,\n",
            "       0.44925425, 0.22166788, 0.11254501, 0.41759204, 1.33994102]),\n",
            " 'std_score_time': array([0.02384668, 0.02435151, 0.17590019, 0.0118517 , 0.04598173,\n",
            "       0.01699644, 0.00978301, 0.00568197, 0.01767331, 0.15917757,\n",
            "       0.01883609, 0.01833942, 0.01198291, 0.03408391, 0.04773061,\n",
            "       0.02988782, 0.01314475, 0.00629325, 0.014122  , 0.03034217,\n",
            "       0.02405176, 0.00840757, 0.01505928, 0.01644476, 0.02514897]),\n",
            " 'std_test_score': array([0.        , 0.        , 0.01732486, 0.        , 0.        ,\n",
            "       0.05187745, 0.05187745, 0.04818201, 0.05187745, 0.05187745,\n",
            "       0.04135505, 0.04135505, 0.03977506, 0.04135505, 0.04135505,\n",
            "       0.04382084, 0.04382084, 0.04382084, 0.04382084, 0.04382084,\n",
            "       0.04382084, 0.04382084, 0.04382084, 0.04382084, 0.04382084])}\n"
          ]
        }
      ],
      "source": [
        "pprint(grid_search_pspp.cv_results_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDUrNLuNM43P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62486b8a-5e6f-423a-ab49-f8ea138f3097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline(steps=[('standardScaler', StandardScaler()),\n",
            "                ('quantiletransformer', QuantileTransformer()),\n",
            "                ('logistic_regression',\n",
            "                 LogisticRegression(penalty='none', solver='newton-cg'))])\n"
          ]
        }
      ],
      "source": [
        "pprint(grid_search_pspp.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPqabVw2NGYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e070b31a-9f26-4f18-8363-3108221871d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('standardScaler', StandardScaler()),\n",
              "                                       ('quantiletransformer',\n",
              "                                        QuantileTransformer()),\n",
              "                                       ('logistic_regression',\n",
              "                                        LogisticRegression())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid=[{'logistic_regression__C': [0.01, 0.1, 1.0, 10.0,\n",
              "                                                     100.0],\n",
              "                          'logistic_regression__penalty': ['none'],\n",
              "                          'logistic_regression__solver': ['newton-cg', 'lbfgs',\n",
              "                                                          'sag', 'saga']}],\n",
              "             scoring='recall', verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "param_grid_pspp = [{\n",
        "    'logistic_regression__solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
        "    'logistic_regression__C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
        "    'logistic_regression__penalty': ['none']\n",
        "}]\n",
        "\n",
        "grid_search_pspp = GridSearchCV(pipe, param_grid_pspp, cv=5, scoring= 'recall', verbose=2, n_jobs=-1)\n",
        "grid_search_pspp.fit(xTrain, yTrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WAFbR3ANrAi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f5f685-fbb8-4b0b-b983-5d17885f9b7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'mean_fit_time': array([ 8.35656333,  6.17518458,  9.59073372, 16.53544998,  8.42137256,\n",
            "        5.45700531,  9.72683573, 16.73693056,  7.83388543,  5.66814079,\n",
            "        9.96281152, 16.15139246,  8.38768883,  5.28316269,  9.21215415,\n",
            "       15.54550443,  7.58168201,  5.67666721,  9.34405022, 14.6911675 ]),\n",
            " 'mean_score_time': array([0.53173752, 0.53239403, 0.4217598 , 0.41385984, 0.51495996,\n",
            "       0.43952479, 0.39896436, 0.4089901 , 0.44433355, 0.44010606,\n",
            "       0.38806386, 0.39944386, 0.46180649, 0.44521809, 0.3779284 ,\n",
            "       0.38667736, 0.42122722, 0.51970048, 0.37006984, 0.36328964]),\n",
            " 'mean_test_score': array([0.76660175, 0.76660175, 0.76660175, 0.76660175, 0.76660175,\n",
            "       0.76660175, 0.76660175, 0.76660175, 0.76660175, 0.76660175,\n",
            "       0.76660175, 0.76660175, 0.76660175, 0.76660175, 0.76660175,\n",
            "       0.76660175, 0.76660175, 0.76660175, 0.76660175, 0.76660175]),\n",
            " 'param_logistic_regression__C': masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 1.0, 1.0,\n",
            "                   1.0, 1.0, 10.0, 10.0, 10.0, 10.0, 100.0, 100.0, 100.0,\n",
            "                   100.0],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object),\n",
            " 'param_logistic_regression__penalty': masked_array(data=['none', 'none', 'none', 'none', 'none', 'none', 'none',\n",
            "                   'none', 'none', 'none', 'none', 'none', 'none', 'none',\n",
            "                   'none', 'none', 'none', 'none', 'none', 'none'],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object),\n",
            " 'param_logistic_regression__solver': masked_array(data=['newton-cg', 'lbfgs', 'sag', 'saga', 'newton-cg',\n",
            "                   'lbfgs', 'sag', 'saga', 'newton-cg', 'lbfgs', 'sag',\n",
            "                   'saga', 'newton-cg', 'lbfgs', 'sag', 'saga',\n",
            "                   'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object),\n",
            " 'params': [{'logistic_regression__C': 0.01,\n",
            "             'logistic_regression__penalty': 'none',\n",
            "             'logistic_regression__solver': 'newton-cg'},\n",
            "            {'logistic_regression__C': 0.01,\n",
            "             'logistic_regression__penalty': 'none',\n",
            "             'logistic_regression__solver': 'lbfgs'},\n",
            "            {'logistic_regression__C': 0.01,\n",
            "             'logistic_regression__penalty': 'none',\n",
            "             'logistic_regression__solver': 'sag'},\n",
            "            {'logistic_regression__C': 0.01,\n",
            "             'logistic_regression__penalty': 'none',\n",
            "             'logistic_regression__solver': 'saga'},\n",
            "            {'logistic_regression__C': 0.1,\n",
            "             'logistic_regression__penalty': 'none',\n",
            "             'logistic_regression__solver': 'newton-cg'},\n",
            "            {'logistic_regression__C': 0.1,\n",
            "             'logistic_regression__penalty': 'none',\n",
            "             'logistic_regression__solver': 'lbfgs'},\n",
            "            {'logistic_regression__C': 0.1,\n",
            "             'logistic_regression__penalty': 'none',\n",
            "             'logistic_regression__solver': 'sag'},\n",
            "            {'logistic_regression__C': 0.1,\n",
            "             'logistic_regression__penalty': 'none',\n",
            "             'logistic_regression__solver': 'saga'},\n",
            "            {'logistic_regression__C': 1.0,\n",
            "             'logistic_regression__penalty': 'none',\n",
            "             'logistic_regression__solver': 'newton-cg'},\n",
            "            {'logistic_regression__C': 1.0,\n",
            "             'logistic_regression__penalty': 'none',\n",
            "             'logistic_regression__solver': 'lbfgs'},\n",
            "            {'logistic_regression__C': 1.0,\n",
            "             'logistic_regression__penalty': 'none',\n",
            "             'logistic_regression__solver': 'sag'},\n",
            "            {'logistic_regression__C': 1.0,\n",
            "             'logistic_regression__penalty': 'none',\n",
            "             'logistic_regression__solver': 'saga'},\n",
            "            {'logistic_regression__C': 10.0,\n",
            "             'logistic_regression__penalty': 'none',\n",
            "             'logistic_regression__solver': 'newton-cg'},\n",
            "            {'logistic_regression__C': 10.0,\n",
            "             'logistic_regression__penalty': 'none',\n",
            "             'logistic_regression__solver': 'lbfgs'},\n",
            "            {'logistic_regression__C': 10.0,\n",
            "             'logistic_regression__penalty': 'none',\n",
            "             'logistic_regression__solver': 'sag'},\n",
            "            {'logistic_regression__C': 10.0,\n",
            "             'logistic_regression__penalty': 'none',\n",
            "             'logistic_regression__solver': 'saga'},\n",
            "            {'logistic_regression__C': 100.0,\n",
            "             'logistic_regression__penalty': 'none',\n",
            "             'logistic_regression__solver': 'newton-cg'},\n",
            "            {'logistic_regression__C': 100.0,\n",
            "             'logistic_regression__penalty': 'none',\n",
            "             'logistic_regression__solver': 'lbfgs'},\n",
            "            {'logistic_regression__C': 100.0,\n",
            "             'logistic_regression__penalty': 'none',\n",
            "             'logistic_regression__solver': 'sag'},\n",
            "            {'logistic_regression__C': 100.0,\n",
            "             'logistic_regression__penalty': 'none',\n",
            "             'logistic_regression__solver': 'saga'}],\n",
            " 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "      dtype=int32),\n",
            " 'split0_test_score': array([0.80769231, 0.80769231, 0.80769231, 0.80769231, 0.80769231,\n",
            "       0.80769231, 0.80769231, 0.80769231, 0.80769231, 0.80769231,\n",
            "       0.80769231, 0.80769231, 0.80769231, 0.80769231, 0.80769231,\n",
            "       0.80769231, 0.80769231, 0.80769231, 0.80769231, 0.80769231]),\n",
            " 'split1_test_score': array([0.69620253, 0.69620253, 0.69620253, 0.69620253, 0.69620253,\n",
            "       0.69620253, 0.69620253, 0.69620253, 0.69620253, 0.69620253,\n",
            "       0.69620253, 0.69620253, 0.69620253, 0.69620253, 0.69620253,\n",
            "       0.69620253, 0.69620253, 0.69620253, 0.69620253, 0.69620253]),\n",
            " 'split2_test_score': array([0.73417722, 0.73417722, 0.73417722, 0.73417722, 0.73417722,\n",
            "       0.73417722, 0.73417722, 0.73417722, 0.73417722, 0.73417722,\n",
            "       0.73417722, 0.73417722, 0.73417722, 0.73417722, 0.73417722,\n",
            "       0.73417722, 0.73417722, 0.73417722, 0.73417722, 0.73417722]),\n",
            " 'split3_test_score': array([0.79746835, 0.79746835, 0.79746835, 0.79746835, 0.79746835,\n",
            "       0.79746835, 0.79746835, 0.79746835, 0.79746835, 0.79746835,\n",
            "       0.79746835, 0.79746835, 0.79746835, 0.79746835, 0.79746835,\n",
            "       0.79746835, 0.79746835, 0.79746835, 0.79746835, 0.79746835]),\n",
            " 'split4_test_score': array([0.79746835, 0.79746835, 0.79746835, 0.79746835, 0.79746835,\n",
            "       0.79746835, 0.79746835, 0.79746835, 0.79746835, 0.79746835,\n",
            "       0.79746835, 0.79746835, 0.79746835, 0.79746835, 0.79746835,\n",
            "       0.79746835, 0.79746835, 0.79746835, 0.79746835, 0.79746835]),\n",
            " 'std_fit_time': array([0.39015099, 0.68274129, 0.39532071, 0.91664633, 0.96854594,\n",
            "       0.35989314, 0.26395149, 1.0684233 , 0.66983819, 0.65983834,\n",
            "       1.30563079, 0.98893262, 1.35332075, 0.17147289, 0.57121645,\n",
            "       0.92713399, 0.64104252, 0.47799449, 1.39948225, 1.8220875 ]),\n",
            " 'std_score_time': array([0.12369507, 0.13611134, 0.01527998, 0.03173106, 0.11950618,\n",
            "       0.02765334, 0.00683771, 0.032094  , 0.03042749, 0.01952973,\n",
            "       0.00590163, 0.0145647 , 0.03753278, 0.03009436, 0.0058802 ,\n",
            "       0.0118732 , 0.02940145, 0.15348389, 0.00417165, 0.03432913]),\n",
            " 'std_test_score': array([0.04382084, 0.04382084, 0.04382084, 0.04382084, 0.04382084,\n",
            "       0.04382084, 0.04382084, 0.04382084, 0.04382084, 0.04382084,\n",
            "       0.04382084, 0.04382084, 0.04382084, 0.04382084, 0.04382084,\n",
            "       0.04382084, 0.04382084, 0.04382084, 0.04382084, 0.04382084])}\n"
          ]
        }
      ],
      "source": [
        "pprint(grid_search_pspp.cv_results_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_pspp = [{\n",
        "    'logistic_regression__solver': ['liblinear', 'saga'],\n",
        "    'logistic_regression__C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
        "    'logistic_regression__penalty': ['l1']\n",
        "}]\n",
        "\n",
        "grid_search_pspp = GridSearchCV(pipe, param_grid_pspp, cv=5, scoring= 'recall', verbose=2, n_jobs=-1)\n",
        "grid_search_pspp.fit(xTrain, yTrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_clpfwQtHayK",
        "outputId": "57bac7ae-2fc9-4ae4-cd9a-12aad6db7917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('standardScaler', StandardScaler()),\n",
              "                                       ('quantiletransformer',\n",
              "                                        QuantileTransformer()),\n",
              "                                       ('logistic_regression',\n",
              "                                        LogisticRegression())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid=[{'logistic_regression__C': [0.01, 0.1, 1.0, 10.0,\n",
              "                                                     100.0],\n",
              "                          'logistic_regression__penalty': ['l1'],\n",
              "                          'logistic_regression__solver': ['liblinear',\n",
              "                                                          'saga']}],\n",
              "             scoring='recall', verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(grid_search_pspp.cv_results_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfMARwXDKhIK",
        "outputId": "88b9b1a8-fb0a-46e0-c6ee-89f3403c86a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'mean_fit_time': array([ 4.67361164,  6.68351402,  8.20449524, 12.76315031, 17.0774261 ,\n",
            "       18.37793341, 25.11043143, 21.75551462, 23.38286572, 21.98476739]),\n",
            " 'mean_score_time': array([0.48502173, 0.47519479, 0.56765399, 0.4524765 , 0.47069955,\n",
            "       0.45157747, 0.47144833, 0.46733499, 0.48290901, 0.46687922]),\n",
            " 'mean_test_score': array([0.        , 0.        , 0.75144434, 0.72859461, 0.76660175,\n",
            "       0.76660175, 0.76660175, 0.76660175, 0.76660175, 0.76660175]),\n",
            " 'param_logistic_regression__C': masked_array(data=[0.01, 0.01, 0.1, 0.1, 1.0, 1.0, 10.0, 10.0, 100.0,\n",
            "                   100.0],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object),\n",
            " 'param_logistic_regression__penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
            "                   'l1'],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object),\n",
            " 'param_logistic_regression__solver': masked_array(data=['liblinear', 'saga', 'liblinear', 'saga', 'liblinear',\n",
            "                   'saga', 'liblinear', 'saga', 'liblinear', 'saga'],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object),\n",
            " 'params': [{'logistic_regression__C': 0.01,\n",
            "             'logistic_regression__penalty': 'l1',\n",
            "             'logistic_regression__solver': 'liblinear'},\n",
            "            {'logistic_regression__C': 0.01,\n",
            "             'logistic_regression__penalty': 'l1',\n",
            "             'logistic_regression__solver': 'saga'},\n",
            "            {'logistic_regression__C': 0.1,\n",
            "             'logistic_regression__penalty': 'l1',\n",
            "             'logistic_regression__solver': 'liblinear'},\n",
            "            {'logistic_regression__C': 0.1,\n",
            "             'logistic_regression__penalty': 'l1',\n",
            "             'logistic_regression__solver': 'saga'},\n",
            "            {'logistic_regression__C': 1.0,\n",
            "             'logistic_regression__penalty': 'l1',\n",
            "             'logistic_regression__solver': 'liblinear'},\n",
            "            {'logistic_regression__C': 1.0,\n",
            "             'logistic_regression__penalty': 'l1',\n",
            "             'logistic_regression__solver': 'saga'},\n",
            "            {'logistic_regression__C': 10.0,\n",
            "             'logistic_regression__penalty': 'l1',\n",
            "             'logistic_regression__solver': 'liblinear'},\n",
            "            {'logistic_regression__C': 10.0,\n",
            "             'logistic_regression__penalty': 'l1',\n",
            "             'logistic_regression__solver': 'saga'},\n",
            "            {'logistic_regression__C': 100.0,\n",
            "             'logistic_regression__penalty': 'l1',\n",
            "             'logistic_regression__solver': 'liblinear'},\n",
            "            {'logistic_regression__C': 100.0,\n",
            "             'logistic_regression__penalty': 'l1',\n",
            "             'logistic_regression__solver': 'saga'}],\n",
            " 'rank_test_score': array([9, 9, 7, 8, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
            " 'split0_test_score': array([0.        , 0.        , 0.82051282, 0.79487179, 0.80769231,\n",
            "       0.80769231, 0.80769231, 0.80769231, 0.80769231, 0.80769231]),\n",
            " 'split1_test_score': array([0.        , 0.        , 0.69620253, 0.64556962, 0.69620253,\n",
            "       0.69620253, 0.69620253, 0.69620253, 0.69620253, 0.69620253]),\n",
            " 'split2_test_score': array([0.        , 0.        , 0.72151899, 0.73417722, 0.73417722,\n",
            "       0.73417722, 0.73417722, 0.73417722, 0.73417722, 0.73417722]),\n",
            " 'split3_test_score': array([0.        , 0.        , 0.73417722, 0.73417722, 0.79746835,\n",
            "       0.79746835, 0.79746835, 0.79746835, 0.79746835, 0.79746835]),\n",
            " 'split4_test_score': array([0.        , 0.        , 0.78481013, 0.73417722, 0.79746835,\n",
            "       0.79746835, 0.79746835, 0.79746835, 0.79746835, 0.79746835]),\n",
            " 'std_fit_time': array([0.10576761, 0.28181648, 1.03795029, 1.79969671, 4.83744145,\n",
            "       1.16624172, 4.57394175, 1.45971345, 4.55268175, 2.8268227 ]),\n",
            " 'std_score_time': array([0.0182576 , 0.01779655, 0.20708334, 0.02195052, 0.02288165,\n",
            "       0.0289193 , 0.03014744, 0.03392279, 0.02989846, 0.09221904]),\n",
            " 'std_test_score': array([0.        , 0.        , 0.04500904, 0.047706  , 0.04382084,\n",
            "       0.04382084, 0.04382084, 0.04382084, 0.04382084, 0.04382084])}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}