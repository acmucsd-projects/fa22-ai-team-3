{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "354f1270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pprint\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66920b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\rohan\\\\Downloads\\\\creditcard.csv\\\\creditcard.csv\")\n",
    "df = df.rename(columns={'Class': 'Fraud'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9488b33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Fraud  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2dfc912",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fraud'] = df['Fraud'].astype(int)\n",
    "\n",
    "X = df.drop(['Fraud'], axis = 1)\n",
    "Y = df[\"Fraud\"]\n",
    "\n",
    "xData = X.values\n",
    "yData = Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ba69550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(\n",
    "        xData, yData, test_size = 0.2, random_state = 42)\n",
    "\n",
    "pipe = Pipeline([('standardScaler', StandardScaler()), ('quantiletransformer', QuantileTransformer()), ('xgb_model', xgb.XGBRegressor())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacdbfab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5c4eb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'standardScaler', 'quantiletransformer', 'xgb_model', 'standardScaler__copy', 'standardScaler__with_mean', 'standardScaler__with_std', 'quantiletransformer__copy', 'quantiletransformer__ignore_implicit_zeros', 'quantiletransformer__n_quantiles', 'quantiletransformer__output_distribution', 'quantiletransformer__random_state', 'quantiletransformer__subsample', 'xgb_model__objective', 'xgb_model__base_score', 'xgb_model__booster', 'xgb_model__colsample_bylevel', 'xgb_model__colsample_bynode', 'xgb_model__colsample_bytree', 'xgb_model__enable_categorical', 'xgb_model__gamma', 'xgb_model__gpu_id', 'xgb_model__importance_type', 'xgb_model__interaction_constraints', 'xgb_model__learning_rate', 'xgb_model__max_delta_step', 'xgb_model__max_depth', 'xgb_model__min_child_weight', 'xgb_model__missing', 'xgb_model__monotone_constraints', 'xgb_model__n_estimators', 'xgb_model__n_jobs', 'xgb_model__num_parallel_tree', 'xgb_model__predictor', 'xgb_model__random_state', 'xgb_model__reg_alpha', 'xgb_model__reg_lambda', 'xgb_model__scale_pos_weight', 'xgb_model__subsample', 'xgb_model__tree_method', 'xgb_model__validate_parameters', 'xgb_model__verbosity'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd0fea9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohan\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.80552632        nan 0.79346749        nan 0.76513158\n",
      "        nan 0.80479102        nan 0.78202786        nan 0.77760062\n",
      "        nan 0.81258514        nan 0.7899226         nan 0.77777864\n",
      "        nan 0.79052632        nan 0.77013158        nan 0.76233746\n",
      "        nan 0.7980418         nan 0.77071981        nan 0.76807276\n",
      "        nan 0.80096749        nan 0.76808824        nan 0.76514706]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('standardScaler', StandardScaler()),\n",
       "                                       ('quantiletransformer',\n",
       "                                        QuantileTransformer()),\n",
       "                                       ('xgb_model',\n",
       "                                        XGBRegressor(base_score=None,\n",
       "                                                     booster=None,\n",
       "                                                     colsample_bylevel=None,\n",
       "                                                     colsample_bynode=None,\n",
       "                                                     colsample_bytree=None,\n",
       "                                                     enable_categorical=False,\n",
       "                                                     gamma=None, gpu_id=None,\n",
       "                                                     importance_type=None,\n",
       "                                                     interaction_constraints=None,\n",
       "                                                     lear...\n",
       "                                                     subsample=None,\n",
       "                                                     tree_method=None,\n",
       "                                                     validate_parameters=None,\n",
       "                                                     verbosity=None))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'xgb_model__booster': ['gbtree', 'dart'],\n",
       "                          'xgb_model__colsample_bytree': [0.3],\n",
       "                          'xgb_model__learning_rate': [0.1],\n",
       "                          'xgb_model__max_depth': [5, 6, 7],\n",
       "                          'xgb_model__n_estimators': [8, 10, 12],\n",
       "                          'xgb_model__objective': ['binary:logistic',\n",
       "                                                   'binary:hinge']}],\n",
       "             scoring='recall', verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_pspp = [{\n",
    "    'xgb_model__objective': ['binary:logistic', 'binary:hinge'],\n",
    "    'xgb_model__booster': ['gbtree', 'dart'],\n",
    "    'xgb_model__colsample_bytree': [0.3],# 0.5, 0.7],\n",
    "    #'xgb_model__gamma': [0, 10, 100, 1000],\n",
    "    'xgb_model__learning_rate': [0.1],# 0.2, 0.3],\n",
    "    'xgb_model__max_depth': [5, 6, 7],\n",
    "    'xgb_model__n_estimators': [8, 10, 12]\n",
    "    #'xgb_model__reg_alpha': [0 ,5, 10, 15],\n",
    "    #'xgb_model__reg_lambda': [0, 5, 10, 15]\n",
    "}]\n",
    "\n",
    "grid_search_pspp = GridSearchCV(pipe, param_grid_pspp, cv=5,\n",
    "                                scoring= 'recall', verbose=2, n_jobs=-1)\n",
    "grid_search_pspp.fit(xTrain, yTrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46f8ea0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('standardScaler', StandardScaler()),\n",
      "                ('quantiletransformer', QuantileTransformer()),\n",
      "                ('xgb_model',\n",
      "                 XGBRegressor(base_score=0.5, booster='gbtree',\n",
      "                              colsample_bylevel=1, colsample_bynode=1,\n",
      "                              colsample_bytree=0.3, enable_categorical=False,\n",
      "                              gamma=0, gpu_id=-1, importance_type=None,\n",
      "                              interaction_constraints='', learning_rate=0.1,\n",
      "                              max_delta_step=0, max_depth=7, min_child_weight=1,\n",
      "                              missing=nan, monotone_constraints='()',\n",
      "                              n_estimators=8, n_jobs=20, num_parallel_tree=1,\n",
      "                              objective='binary:hinge', predictor='auto',\n",
      "                              random_state=0, reg_alpha=0, reg_lambda=1,\n",
      "                              scale_pos_weight=None, subsample=1,\n",
      "                              tree_method='exact', validate_parameters=1,\n",
      "                              verbosity=None))])\n"
     ]
    }
   ],
   "source": [
    "pprint(grid_search_pspp.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47540db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([21.03659239, 22.65926762, 29.26532531, 33.91242285, 48.55281668,\n",
      "       52.25514712, 36.43403978, 42.38896689, 42.06590977, 45.44814377,\n",
      "       50.73091149, 59.89149408, 47.86006565, 53.0806654 , 50.65715575,\n",
      "       56.69640517, 56.52972412, 70.71507387, 36.37240624, 42.40468192,\n",
      "       57.60131078, 58.10762196, 67.10148849, 66.25685163, 56.0440938 ,\n",
      "       56.80706639, 60.50241933, 61.74115024, 69.70695004, 71.51275816,\n",
      "       57.72516446, 61.8824059 , 67.17366347, 64.17221484, 57.55198793,\n",
      "       49.95115647]),\n",
      " 'mean_score_time': array([2.64330153, 1.76032686, 4.44676261, 1.99385829, 2.96903715,\n",
      "       2.67498827, 1.61726041, 1.97274818, 1.51480236, 2.21158957,\n",
      "       3.17629356, 2.29648948, 1.30930243, 1.419557  , 2.30339098,\n",
      "       1.44483762, 1.79181762, 2.31988287, 4.34414387, 3.15176764,\n",
      "       4.36681557, 5.04170518, 5.21592522, 5.48976407, 2.99022031,\n",
      "       4.50477786, 3.75927296, 5.34031763, 3.72966728, 5.80294633,\n",
      "       3.80834541, 4.98652368, 3.29037352, 2.53607974, 2.37791724,\n",
      "       1.59837608]),\n",
      " 'mean_test_score': array([       nan, 0.80552632,        nan, 0.79346749,        nan,\n",
      "       0.76513158,        nan, 0.80479102,        nan, 0.78202786,\n",
      "              nan, 0.77760062,        nan, 0.81258514,        nan,\n",
      "       0.7899226 ,        nan, 0.77777864,        nan, 0.79052632,\n",
      "              nan, 0.77013158,        nan, 0.76233746,        nan,\n",
      "       0.7980418 ,        nan, 0.77071981,        nan, 0.76807276,\n",
      "              nan, 0.80096749,        nan, 0.76808824,        nan,\n",
      "       0.76514706]),\n",
      " 'param_xgb_model__booster': masked_array(data=['gbtree', 'gbtree', 'gbtree', 'gbtree', 'gbtree',\n",
      "                   'gbtree', 'gbtree', 'gbtree', 'gbtree', 'gbtree',\n",
      "                   'gbtree', 'gbtree', 'gbtree', 'gbtree', 'gbtree',\n",
      "                   'gbtree', 'gbtree', 'gbtree', 'dart', 'dart', 'dart',\n",
      "                   'dart', 'dart', 'dart', 'dart', 'dart', 'dart', 'dart',\n",
      "                   'dart', 'dart', 'dart', 'dart', 'dart', 'dart', 'dart',\n",
      "                   'dart'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_xgb_model__colsample_bytree': masked_array(data=[0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_xgb_model__learning_rate': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_xgb_model__max_depth': masked_array(data=[5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,\n",
      "                   5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_xgb_model__n_estimators': masked_array(data=[8, 8, 10, 10, 12, 12, 8, 8, 10, 10, 12, 12, 8, 8, 10,\n",
      "                   10, 12, 12, 8, 8, 10, 10, 12, 12, 8, 8, 10, 10, 12, 12,\n",
      "                   8, 8, 10, 10, 12, 12],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_xgb_model__objective': masked_array(data=['binary:logistic', 'binary:hinge', 'binary:logistic',\n",
      "                   'binary:hinge', 'binary:logistic', 'binary:hinge',\n",
      "                   'binary:logistic', 'binary:hinge', 'binary:logistic',\n",
      "                   'binary:hinge', 'binary:logistic', 'binary:hinge',\n",
      "                   'binary:logistic', 'binary:hinge', 'binary:logistic',\n",
      "                   'binary:hinge', 'binary:logistic', 'binary:hinge',\n",
      "                   'binary:logistic', 'binary:hinge', 'binary:logistic',\n",
      "                   'binary:hinge', 'binary:logistic', 'binary:hinge',\n",
      "                   'binary:logistic', 'binary:hinge', 'binary:logistic',\n",
      "                   'binary:hinge', 'binary:logistic', 'binary:hinge',\n",
      "                   'binary:logistic', 'binary:hinge', 'binary:logistic',\n",
      "                   'binary:hinge', 'binary:logistic', 'binary:hinge'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'params': [{'xgb_model__booster': 'gbtree',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 5,\n",
      "             'xgb_model__n_estimators': 8,\n",
      "             'xgb_model__objective': 'binary:logistic'},\n",
      "            {'xgb_model__booster': 'gbtree',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 5,\n",
      "             'xgb_model__n_estimators': 8,\n",
      "             'xgb_model__objective': 'binary:hinge'},\n",
      "            {'xgb_model__booster': 'gbtree',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 5,\n",
      "             'xgb_model__n_estimators': 10,\n",
      "             'xgb_model__objective': 'binary:logistic'},\n",
      "            {'xgb_model__booster': 'gbtree',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 5,\n",
      "             'xgb_model__n_estimators': 10,\n",
      "             'xgb_model__objective': 'binary:hinge'},\n",
      "            {'xgb_model__booster': 'gbtree',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 5,\n",
      "             'xgb_model__n_estimators': 12,\n",
      "             'xgb_model__objective': 'binary:logistic'},\n",
      "            {'xgb_model__booster': 'gbtree',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 5,\n",
      "             'xgb_model__n_estimators': 12,\n",
      "             'xgb_model__objective': 'binary:hinge'},\n",
      "            {'xgb_model__booster': 'gbtree',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 6,\n",
      "             'xgb_model__n_estimators': 8,\n",
      "             'xgb_model__objective': 'binary:logistic'},\n",
      "            {'xgb_model__booster': 'gbtree',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 6,\n",
      "             'xgb_model__n_estimators': 8,\n",
      "             'xgb_model__objective': 'binary:hinge'},\n",
      "            {'xgb_model__booster': 'gbtree',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 6,\n",
      "             'xgb_model__n_estimators': 10,\n",
      "             'xgb_model__objective': 'binary:logistic'},\n",
      "            {'xgb_model__booster': 'gbtree',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 6,\n",
      "             'xgb_model__n_estimators': 10,\n",
      "             'xgb_model__objective': 'binary:hinge'},\n",
      "            {'xgb_model__booster': 'gbtree',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 6,\n",
      "             'xgb_model__n_estimators': 12,\n",
      "             'xgb_model__objective': 'binary:logistic'},\n",
      "            {'xgb_model__booster': 'gbtree',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 6,\n",
      "             'xgb_model__n_estimators': 12,\n",
      "             'xgb_model__objective': 'binary:hinge'},\n",
      "            {'xgb_model__booster': 'gbtree',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 7,\n",
      "             'xgb_model__n_estimators': 8,\n",
      "             'xgb_model__objective': 'binary:logistic'},\n",
      "            {'xgb_model__booster': 'gbtree',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 7,\n",
      "             'xgb_model__n_estimators': 8,\n",
      "             'xgb_model__objective': 'binary:hinge'},\n",
      "            {'xgb_model__booster': 'gbtree',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 7,\n",
      "             'xgb_model__n_estimators': 10,\n",
      "             'xgb_model__objective': 'binary:logistic'},\n",
      "            {'xgb_model__booster': 'gbtree',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 7,\n",
      "             'xgb_model__n_estimators': 10,\n",
      "             'xgb_model__objective': 'binary:hinge'},\n",
      "            {'xgb_model__booster': 'gbtree',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 7,\n",
      "             'xgb_model__n_estimators': 12,\n",
      "             'xgb_model__objective': 'binary:logistic'},\n",
      "            {'xgb_model__booster': 'gbtree',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 7,\n",
      "             'xgb_model__n_estimators': 12,\n",
      "             'xgb_model__objective': 'binary:hinge'},\n",
      "            {'xgb_model__booster': 'dart',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 5,\n",
      "             'xgb_model__n_estimators': 8,\n",
      "             'xgb_model__objective': 'binary:logistic'},\n",
      "            {'xgb_model__booster': 'dart',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 5,\n",
      "             'xgb_model__n_estimators': 8,\n",
      "             'xgb_model__objective': 'binary:hinge'},\n",
      "            {'xgb_model__booster': 'dart',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 5,\n",
      "             'xgb_model__n_estimators': 10,\n",
      "             'xgb_model__objective': 'binary:logistic'},\n",
      "            {'xgb_model__booster': 'dart',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 5,\n",
      "             'xgb_model__n_estimators': 10,\n",
      "             'xgb_model__objective': 'binary:hinge'},\n",
      "            {'xgb_model__booster': 'dart',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 5,\n",
      "             'xgb_model__n_estimators': 12,\n",
      "             'xgb_model__objective': 'binary:logistic'},\n",
      "            {'xgb_model__booster': 'dart',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 5,\n",
      "             'xgb_model__n_estimators': 12,\n",
      "             'xgb_model__objective': 'binary:hinge'},\n",
      "            {'xgb_model__booster': 'dart',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 6,\n",
      "             'xgb_model__n_estimators': 8,\n",
      "             'xgb_model__objective': 'binary:logistic'},\n",
      "            {'xgb_model__booster': 'dart',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 6,\n",
      "             'xgb_model__n_estimators': 8,\n",
      "             'xgb_model__objective': 'binary:hinge'},\n",
      "            {'xgb_model__booster': 'dart',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 6,\n",
      "             'xgb_model__n_estimators': 10,\n",
      "             'xgb_model__objective': 'binary:logistic'},\n",
      "            {'xgb_model__booster': 'dart',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 6,\n",
      "             'xgb_model__n_estimators': 10,\n",
      "             'xgb_model__objective': 'binary:hinge'},\n",
      "            {'xgb_model__booster': 'dart',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 6,\n",
      "             'xgb_model__n_estimators': 12,\n",
      "             'xgb_model__objective': 'binary:logistic'},\n",
      "            {'xgb_model__booster': 'dart',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 6,\n",
      "             'xgb_model__n_estimators': 12,\n",
      "             'xgb_model__objective': 'binary:hinge'},\n",
      "            {'xgb_model__booster': 'dart',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 7,\n",
      "             'xgb_model__n_estimators': 8,\n",
      "             'xgb_model__objective': 'binary:logistic'},\n",
      "            {'xgb_model__booster': 'dart',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 7,\n",
      "             'xgb_model__n_estimators': 8,\n",
      "             'xgb_model__objective': 'binary:hinge'},\n",
      "            {'xgb_model__booster': 'dart',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 7,\n",
      "             'xgb_model__n_estimators': 10,\n",
      "             'xgb_model__objective': 'binary:logistic'},\n",
      "            {'xgb_model__booster': 'dart',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 7,\n",
      "             'xgb_model__n_estimators': 10,\n",
      "             'xgb_model__objective': 'binary:hinge'},\n",
      "            {'xgb_model__booster': 'dart',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 7,\n",
      "             'xgb_model__n_estimators': 12,\n",
      "             'xgb_model__objective': 'binary:logistic'},\n",
      "            {'xgb_model__booster': 'dart',\n",
      "             'xgb_model__colsample_bytree': 0.3,\n",
      "             'xgb_model__learning_rate': 0.1,\n",
      "             'xgb_model__max_depth': 7,\n",
      "             'xgb_model__n_estimators': 12,\n",
      "             'xgb_model__objective': 'binary:hinge'}],\n",
      " 'rank_test_score': array([36,  2, 20,  6, 22, 17, 25,  3, 27,  9, 30, 11, 32,  1, 35,  8, 19,\n",
      "       10, 33,  7, 31, 13, 29, 18, 28,  5, 26, 12, 24, 15, 23,  4, 21, 14,\n",
      "       34, 16]),\n",
      " 'split0_test_score': array([       nan, 0.83823529,        nan, 0.83823529,        nan,\n",
      "       0.80882353,        nan, 0.82352941,        nan, 0.80882353,\n",
      "              nan, 0.80882353,        nan, 0.83823529,        nan,\n",
      "       0.80882353,        nan, 0.82352941,        nan, 0.82352941,\n",
      "              nan, 0.80882353,        nan, 0.79411765,        nan,\n",
      "       0.83823529,        nan, 0.82352941,        nan, 0.82352941,\n",
      "              nan, 0.83823529,        nan, 0.82352941,        nan,\n",
      "       0.80882353]),\n",
      " 'split1_test_score': array([       nan, 0.77647059,        nan, 0.74117647,        nan,\n",
      "       0.72941176,        nan, 0.78823529,        nan, 0.77647059,\n",
      "              nan, 0.74117647,        nan, 0.78823529,        nan,\n",
      "       0.77647059,        nan, 0.75294118,        nan, 0.74117647,\n",
      "              nan, 0.72941176,        nan, 0.71764706,        nan,\n",
      "       0.75294118,        nan, 0.72941176,        nan, 0.72941176,\n",
      "              nan, 0.74117647,        nan, 0.72941176,        nan,\n",
      "       0.71764706]),\n",
      " 'split2_test_score': array([       nan, 0.80263158,        nan, 0.80263158,        nan,\n",
      "       0.76315789,        nan, 0.80263158,        nan, 0.77631579,\n",
      "              nan, 0.78947368,        nan, 0.80263158,        nan,\n",
      "       0.81578947,        nan, 0.76315789,        nan, 0.80263158,\n",
      "              nan, 0.76315789,        nan, 0.76315789,        nan,\n",
      "       0.78947368,        nan, 0.76315789,        nan, 0.76315789,\n",
      "              nan, 0.80263158,        nan, 0.75      ,        nan,\n",
      "       0.75      ]),\n",
      " 'split3_test_score': array([   nan, 0.775 ,    nan, 0.75  ,    nan, 0.7125,    nan, 0.7625,\n",
      "          nan, 0.725 ,    nan, 0.725 ,    nan, 0.775 ,    nan, 0.725 ,\n",
      "          nan, 0.7375,    nan, 0.75  ,    nan, 0.7375,    nan, 0.725 ,\n",
      "          nan, 0.7625,    nan, 0.7375,    nan, 0.7125,    nan, 0.7875,\n",
      "          nan, 0.7375,    nan, 0.7375]),\n",
      " 'split4_test_score': array([       nan, 0.83529412,        nan, 0.83529412,        nan,\n",
      "       0.81176471,        nan, 0.84705882,        nan, 0.82352941,\n",
      "              nan, 0.82352941,        nan, 0.85882353,        nan,\n",
      "       0.82352941,        nan, 0.81176471,        nan, 0.83529412,\n",
      "              nan, 0.81176471,        nan, 0.81176471,        nan,\n",
      "       0.84705882,        nan, 0.8       ,        nan, 0.81176471,\n",
      "              nan, 0.83529412,        nan, 0.8       ,        nan,\n",
      "       0.81176471]),\n",
      " 'std_fit_time': array([0.26652068, 0.48515956, 0.83447201, 1.01755737, 0.71788492,\n",
      "       1.04730323, 0.93280317, 1.18922631, 0.84892826, 0.7783976 ,\n",
      "       1.87799376, 1.19975553, 0.20171065, 1.13261747, 0.62794776,\n",
      "       0.93798227, 0.26346462, 0.58057827, 0.51862336, 0.40653302,\n",
      "       0.60875835, 1.24432805, 0.62162989, 0.83451028, 0.66889544,\n",
      "       1.46503749, 0.31284495, 0.90016732, 0.46136114, 0.6308491 ,\n",
      "       0.69160373, 0.53712474, 0.40684865, 1.58591989, 1.67066906,\n",
      "       0.90984178]),\n",
      " 'std_score_time': array([0.44938748, 0.33172683, 0.42105436, 0.61699469, 0.68587964,\n",
      "       0.53430574, 0.43083955, 0.79504981, 0.15145468, 0.15948048,\n",
      "       0.58568906, 0.18345141, 0.16793013, 0.11098311, 0.42918724,\n",
      "       0.14417359, 0.19231635, 0.49434592, 0.58796181, 0.16299265,\n",
      "       0.39113821, 0.75286486, 0.72365324, 0.29015937, 0.27183547,\n",
      "       0.41686995, 0.6098266 , 0.23328126, 0.20130044, 0.37431395,\n",
      "       0.24456528, 0.06838735, 0.27905056, 0.12767968, 0.31601389,\n",
      "       0.51010139]),\n",
      " 'std_test_score': array([       nan, 0.02735131,        nan, 0.04113728,        nan,\n",
      "       0.04033242,        nan, 0.02899993,        nan, 0.03392956,\n",
      "              nan, 0.03825921,        nan, 0.03130671,        nan,\n",
      "       0.0361985 ,        nan, 0.0337675 ,        nan, 0.03825621,\n",
      "              nan, 0.03464662,        nan, 0.03700006,        nan,\n",
      "       0.03844186,        nan, 0.03609232,        nan, 0.0437986 ,\n",
      "              nan, 0.03557054,        nan, 0.03701561,        nan,\n",
      "       0.03829068])}\n"
     ]
    }
   ],
   "source": [
    "pprint(grid_search_pspp.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab1ab1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd80f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d952a099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
